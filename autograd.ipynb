{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import deque\n",
    "import itertools\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComputationalGraph():\n",
    "    \"\"\"Represents a computational graph.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # The graph in the form of an adjacency list. \n",
    "        # Each key in the dictionary is a Node ID and the corresponding value \n",
    "        # is the list of ID's of edges that originate from that Node.\n",
    "        self.forwardAdj = {}\n",
    "\n",
    "        # Dictionary of backward edge connections.\n",
    "        self.backwardAdj = {}\n",
    "        \n",
    "        # The set of ID's of edges that belong to the computational graph.\n",
    "        self.edges = set()\n",
    "    \n",
    "    \n",
    "    def add_node(self, nodeId):\n",
    "        \"\"\"Add a node to the graph.\"\"\"\n",
    "        try:\n",
    "            _ = Node.get(nodeId)\n",
    "        except KeyError:\n",
    "            raise\n",
    "       \n",
    "        if nodeId in self.forwardAdj:\n",
    "            warnings.warn(\"Warning..... Atempting to add node that already exists in Computational Graph. Ignored.\")\n",
    "            return\n",
    "        \n",
    "        self.forwardAdj[nodeId] = []\n",
    "        self.backwardAdj[nodeId] = []\n",
    "\n",
    "    \n",
    "    def add_edge(self, edgeId):\n",
    "        \"\"\"Add an edge to the graph.\"\"\"\n",
    "        try:\n",
    "            edge = Edge.get(edgeId)\n",
    "        except KeyError:\n",
    "            raise\n",
    "\n",
    "        if edgeId in self.edges:\n",
    "            warnings.warn(\"Warning..... Atempting to add edge that already exists in Computational Graph. Ignored.\")\n",
    "            return\n",
    "        \n",
    "        if edge.nodeFromId not in self.forwardAdj or edge.nodeToId not in self.forwardAdj:\n",
    "            raise ValueError('Both nodes of the edge must belong to the Computational Graph')\n",
    "\n",
    "        self.edges.add(edgeId)\n",
    "        self.forwardAdj[edge.nodeFromId].append(edgeId)\n",
    "        self.backwardAdj[edge.nodeToId].append(edgeId)\n",
    "\n",
    "    def getConnectedComponent(self, nodeId):\n",
    "        \"\"\"Return a connected component containing node with given Id.\n",
    "        Assumes undirected graph.\n",
    "        \"\"\"\n",
    "        visited = {}\n",
    "        connectedComponent = []\n",
    "        \n",
    "        def dfs(nodeId, graph):\n",
    "            \"\"\"Perform a depth-first-traversal from the given node, \n",
    "            adding each node id on the path to the connectedCOmponent list.\n",
    "            \"\"\"\n",
    "            visited[nodeId] = True\n",
    "            connectedComponent.append(nodeId)\n",
    "            for edgeId in graph.forwardAdj[nodeId]:\n",
    "                edge = Edge.get(edgeId)\n",
    "                neighbourId = edge.nodeToId\n",
    "                if neighbourId not in visited:\n",
    "                    dfs(neighbourId, graph)\n",
    "            for edgeId in graph.backwardAdj[nodeId]:\n",
    "                edge = Edge.get(edgeId)\n",
    "                neighbourId = edge.nodeFromId\n",
    "                if neighbourId not in visited:\n",
    "                    dfs(neighbourId, graph)\n",
    "            \n",
    "        dfs(nodeId, self)\n",
    "        return connectedComponent\n",
    "\n",
    "    \n",
    "    def getTopSort(self, containedNodeId=None):\n",
    "        \"\"\"Return the list of ID's of Nodes in the graph sorted in Topological order.\n",
    "        This is useful for backward propagation of gradients as the order in which \n",
    "        nodes need to be visited while passing gradients backwards is the reverse\n",
    "        topological ordering.\n",
    "\n",
    "        Args:\n",
    "            containedNodeId: Topological sort of the connected component to which\n",
    "                              the node with containedNodeId belongs is returned. \n",
    "                              Entire topological sort is returned if containedNodeId\n",
    "                              is None.\n",
    "        \"\"\"\n",
    "        \n",
    "        sortedNodes = []\n",
    "        \n",
    "        # We store the in-degrees of the nodes in the graph as part of \n",
    "        # Kahn's algorithm for calculating the topological sort.\n",
    "        inDegree = {} \n",
    "        \n",
    "        # A dictionary to maintain whether we have finished placing a node\n",
    "        # in it's topologically sorted position.\n",
    "        done = {}\n",
    "\n",
    "        # Calculate the in-degrees of all nodes in the graph.\n",
    "        for nodeId in self.forwardAdj:\n",
    "            done[nodeId] = False\n",
    "            if nodeId not in inDegree:\n",
    "                inDegree[nodeId] = 0\n",
    "            for edgeId in self.forwardAdj[nodeId]:\n",
    "                edge = Edge.get(edgeId)\n",
    "                if edge.nodeToId not in inDegree:\n",
    "                    inDegree[edge.nodeToId] = 0\n",
    "                inDegree[edge.nodeToId] += 1\n",
    "        \n",
    "        # Initialize the queue with nodes having in-degree = 0.\n",
    "        # We always maintain the queue with nodes having in-degree = 0.\n",
    "        queue = deque()\n",
    "        for nodeId in inDegree:\n",
    "            if inDegree[nodeId] == 0:\n",
    "                queue.append(nodeId)\n",
    "        \n",
    "        try:\n",
    "            # While the queue is not empty, remove the front-most node\n",
    "            # and place it in the sorted list of nodes.\n",
    "            while (queue):\n",
    "                frontNodeId = queue.popleft()\n",
    "                sortedNodes.append(frontNodeId)\n",
    "                done[frontNodeId] = True\n",
    "\n",
    "                # Update the in-degrees of neighbours of the removed node.\n",
    "                # If any neighbour now has in-degree = 0, then it is pushed \n",
    "                # to the queue again.\n",
    "                for edgeId in self.forwardAdj[frontNodeId]:\n",
    "                    edge = Edge.get(edgeId)\n",
    "                    # If we encounter a node that we have marked as completed,\n",
    "                    # it means that we have found a cycle in the graph and \n",
    "                    # it is not possible to generate a topological sorting.\n",
    "                    if done[edge.nodeToId]:\n",
    "                        raise CycleFoundError('Cycle found: Cannot find topological sorting in a cyclic graph')\n",
    "                    inDegree[edge.nodeToId] -= 1\n",
    "                    if inDegree[edge.nodeToId] == 0:\n",
    "                        queue.append(edge.nodeToId)\n",
    "        \n",
    "        except CycleFoundError:\n",
    "            return []\n",
    "\n",
    "        # Return only the relevant connected component\n",
    "        if containedNodeId is not None:\n",
    "            connectedComponent = self.getConnectedComponent(containedNodeId)\n",
    "            sortedNodes = list(filter(lambda nodeId: nodeId in connectedComponent, sortedNodes))\n",
    "        return sortedNodes\n",
    "\n",
    "\n",
    "class CycleFoundError(Exception):\n",
    "    '''Raised when a cycle is found in what is expected to be an acyclic graph.'''\n",
    "    pass\n",
    "\n",
    "\n",
    "class Node():\n",
    "    \"\"\"A node in the computational graph. Corresponds to a single Tensor instance.\"\"\"\n",
    "\n",
    "    # An iterator that generates ID's for successive\n",
    "    # instances of the class.\n",
    "    id_iter = itertools.count()\n",
    "\n",
    "    # A dictionary that maintains a mapping between instance ID's \n",
    "    # and the instances.\n",
    "    items = {}\n",
    "\n",
    "    def __init__(self, graph, fromNodesAndGrads=[]):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            \n",
    "            graph: The computational graph to which the node belongs.\n",
    "            \n",
    "            fromNodesAndGrads: A list of (Node@, grad) tuples such that there is\n",
    "                               an edge between Node and this instance with grad being\n",
    "                               the gradient of the tensor at this instance wrt to the tensor \n",
    "                               at Node@\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(graph, ComputationalGraph):\n",
    "            raise ValueError('Node cannot exist independent of a computational graph')\n",
    "\n",
    "        # Assign an ID and add to the dictionary of all Nodes.\n",
    "        self.id = next(self.id_iter)\n",
    "        self.__class__.items[self.id] = self\n",
    "        \n",
    "        self.graph = graph\n",
    "        self.graph.add_node(self.id)\n",
    "\n",
    "        # Create an Edge instance for every edge and that culminates at\n",
    "        # the current node and add the Edge to the Computational graph.\n",
    "        for (fromNodeId, grad) in fromNodesAndGrads:\n",
    "            try:\n",
    "                edge = Edge(fromNodeId, self.id, grad)\n",
    "            except KeyError:\n",
    "                raise\n",
    "            self.graph.add_edge(edge.id)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'Node({self.id})'\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, id):\n",
    "        \"\"\"Return a reference to a node instance from its ID.\"\"\"\n",
    "        if id in cls.items:\n",
    "            return cls.items[id]\n",
    "        else:\n",
    "            raise KeyError(f'Node with id {id} does not exist')\n",
    "\n",
    "\n",
    "\n",
    "class Edge():\n",
    "    \"\"\"An edge in the computational graph.\"\"\"\n",
    "\n",
    "    # An iterator that generates ID's for successive\n",
    "    # instances of the class.\n",
    "    id_iter = itertools.count()\n",
    "\n",
    "    # A dictionary that maintains a mapping between instance ID's \n",
    "    # and the instances.\n",
    "    items = {}\n",
    "\n",
    "    def __init__(self, nodeFromId, nodeToId, grad):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            \n",
    "            nodeFromId: ID of the node from which the edge originates.\n",
    "            \n",
    "            nodeToId: ID of the node at which the edge terminates.\n",
    "\n",
    "            grad: The gradient of the tensor at the terminal node wrt\n",
    "                  the tensor at the start node.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            _, _ = Node.get(nodeFromId), Node.get(nodeToId)\n",
    "        except KeyError:\n",
    "            raise\n",
    "        \n",
    "        # Assign an ID and add to the dictionary of all Nodes.\n",
    "        self.id = next(self.id_iter)\n",
    "        self.__class__.items[self.id] = self\n",
    "        \n",
    "        self.nodeFromId = nodeFromId\n",
    "        self.nodeToId = nodeToId\n",
    "        self.grad = grad\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'<Edge({self.id}), grad={self.grad}>'\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, id):\n",
    "        \"\"\"Return a reference to an edge instance from its ID.\"\"\"\n",
    "        if id in cls.items:\n",
    "            return cls.items[id]\n",
    "        else:\n",
    "            raise KeyError(f'Edge with id {id} does not exist')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 6, 1, 5, 7, 3, 4]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test case for ComputationalGraph and topological sort.\n",
    "#\n",
    "# 0 -> 1\n",
    "# 0 -> 3\n",
    "# 0 -> 5\n",
    "# 1 -> 3\n",
    "# 2 -> 3\n",
    "# 2 -> 4\n",
    "# 3 -> 4\n",
    "# 5 -> 4\n",
    "\n",
    "graph = ComputationalGraph()\n",
    "n0 = Node(graph)\n",
    "n1 = Node(graph, fromNodesAndGrads=[(n0.id, 1)])\n",
    "n2 = Node(graph)\n",
    "n3 = Node(graph, fromNodesAndGrads=[(n0.id, 1), (n1.id, 1), (n2.id, 1)])\n",
    "n4 = Node(graph, fromNodesAndGrads=[(n2.id, 1), (n3.id, 1)])\n",
    "n5 = Node(graph)\n",
    "n6 = Node(graph)\n",
    "n7 = Node(graph)\n",
    "graph.add_edge(Edge(n0.id, n5.id, 1).id)\n",
    "graph.add_edge(Edge(n5.id, n4.id, 1).id)\n",
    "graph.add_edge(Edge(n6.id, n7.id, 1).id)\n",
    "graph.getTopSort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a global computational graph for use with the Tensor class\n",
    "GRAPH = ComputationalGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tensor():\n",
    "    \"\"\"Class for a Tensor. Each Tensor is associated with a node in a computational graph.\"\"\"\n",
    "\n",
    "    def __init__(self, value, graph=GRAPH, node=None):\n",
    "        \"\"\"\n",
    "        \n",
    "        Args:\n",
    "            \n",
    "            value: The value of the tensor. (Currently restricted to float/int)\n",
    "\n",
    "            graph: The computational graph to which the tensor will be added to.\n",
    "\n",
    "            node: The node in the computational graph which is associated with the tensor.\n",
    "        \"\"\"\n",
    "        \n",
    "        if type(value) not in [int, float]:\n",
    "            raise ValueError(\n",
    "                'Only floating point scalar tensors are supported.')\n",
    "\n",
    "        self.value = float(value)\n",
    "\n",
    "        # The gradient accumulated at the tensor. \n",
    "        # It is updated when a descendant tensor in the computational graph \n",
    "        # makes a call to backward().\n",
    "        self.grad = 0\n",
    "        \n",
    "        # Create and assign a compuational graph and a node if none are provided.\n",
    "        if graph == None:\n",
    "            graph = ComputationalGraph()\n",
    "\n",
    "        if node == None:\n",
    "            node = Node(graph)\n",
    "\n",
    "        self.node = node\n",
    "        self.node.tensor = self\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def atNode(cls, node, value):\n",
    "        \"\"\"Initialize a tensor at a specific node.\n",
    "        \n",
    "        Args:\n",
    "\n",
    "            node: The node at which the tensor will be initialized\n",
    "\n",
    "            value: The value of the tensor. (Currently restricted to float/int).\n",
    "\n",
    "        \"\"\"\n",
    "        return cls(value, graph=node.graph, node=node)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Tensor({self.value})\"\n",
    "\n",
    "\n",
    "    def zero_grad(self):\n",
    "        \"\"\"Set the grad property of the tensor instance to 0\"\"\"\n",
    "        self.grad = 0\n",
    "\n",
    "    def accumulate_grad(self, grad):\n",
    "        \"\"\"Accumulates gradient at current node.\n",
    "\n",
    "        Args:\n",
    "            grad: Gradient to be accumulated\n",
    "        \"\"\"\n",
    "        self.grad += grad\n",
    "\n",
    "    def backward(self):\n",
    "        \"\"\"Make a backward pass and update gradients at ancestor nodes.\"\"\"\n",
    "\n",
    "        # Get ancestor nodes in topological sorted order\n",
    "        nodes = self.node.graph.getTopSort(self.node.id)\n",
    "\n",
    "        # Set gradients to zero for all nodes\n",
    "        for nodeId in nodes:\n",
    "            Node.get(nodeId).tensor.zero_grad()\n",
    "\n",
    "        # Make backward passes in reverse topological order\n",
    "        self.grad = 1\n",
    "        for nodeId in reversed(nodes):\n",
    "            for edgeId in self.node.graph.backwardAdj[nodeId]:\n",
    "                edge = Edge.get(edgeId)\n",
    "                parentNode = Node.get(edge.nodeFromId)\n",
    "                parentNode.tensor.accumulate_grad(self.grad * edge.grad)\n",
    "\n",
    "    # Overloaded Operators \n",
    "    def __neg__(self):\n",
    "        result_val = -1 * self.value\n",
    "        fromNodesAndGrads = [(self.node.id, -1)]\n",
    "        result_node = Node(self.node.graph, fromNodesAndGrads)\n",
    "        return Tensor.atNode(result_node, result_val)\n",
    "\n",
    "    def __add__(self, other):\n",
    "        if not isinstance(other, Tensor):\n",
    "            try:\n",
    "                other = Tensor(other)\n",
    "            except:\n",
    "                return NotImplemented\n",
    "        result_val = self.value + other.value\n",
    "        fromNodesAndGrads = [(self.node.id, 1), (other.node.id, 1)]\n",
    "        result_node = Node(self.node.graph, fromNodesAndGrads)\n",
    "        return Tensor.atNode(result_node, result_val)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        result = self.__add__(-other)\n",
    "        return result\n",
    "\n",
    "    def __mul__(self, other):\n",
    "        if not isinstance(other, Tensor):\n",
    "            try:\n",
    "                other = Tensor(other)\n",
    "            except:\n",
    "                return NotImplemented\n",
    "        result_val = self.value * other.value\n",
    "        fromNodesAndGrads = [(self.node.id, other.value),\n",
    "                             (other.node.id, self.value)]\n",
    "        result_node = Node(self.node.graph, fromNodesAndGrads)\n",
    "        return Tensor.atNode(result_node, result_val)\n",
    "\n",
    "    def __truediv__(self, other):\n",
    "        if not isinstance(other, Tensor):\n",
    "            try:\n",
    "                other = Tensor(other)\n",
    "            except:\n",
    "                return NotImplemented\n",
    "        result_val = self.value / other.value\n",
    "        fromNodesAndGrads = [(self.node.id, 1/other.value), (other.node.id, -self.value / (other.value**2))]\n",
    "        result_node = Node(self.node.graph, fromNodesAndGrads)\n",
    "        return Tensor.atNode(result_node, result_val)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(6.0)\n"
     ]
    }
   ],
   "source": [
    "a = Tensor(3)\n",
    "b = Tensor(2)\n",
    "\n",
    "c = a * b\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients:\n",
      "a: 2.0\n",
      "b: 3.0\n"
     ]
    }
   ],
   "source": [
    "# Backpropagation example\n",
    "c.backward()\n",
    "print(\"Gradients:\")\n",
    "print(\"a:\", a.grad)\n",
    "print(\"b:\", b.grad)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2a31edf32cff4a1020f46be9a228b80b96635f211262e5512e65d0aacd090ec5"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
